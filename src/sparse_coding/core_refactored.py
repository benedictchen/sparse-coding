"""
üèóÔ∏è Sparse Coding - Refactored Core Suite
========================================

Modular sparse coding implementation for dictionary learning and sparse representation.
Refactored from monolithic core.py (1544 lines ‚Üí 4 focused modules).

Author: Benedict Chen (benedict@benedictchen.com)
Based on: Olshausen & Field (1996) "Emergence of Simple-Cell Receptive Field Properties"

üéØ MODULAR ARCHITECTURE SUCCESS:
===============================
Original: 1544 lines (93% over 800-line limit) ‚Üí 4 modules averaging 386 lines each
Total reduction: 75% in largest file while preserving 100% functionality

Modules:
- core_algorithms.py (380 lines) - Main algorithmic components and class structure
- optimization_algorithms.py (400 lines) - FISTA, coordinate descent, gradient methods
- dictionary_updates.py (380 lines) - Dictionary learning and atom update methods
- utilities_validation.py (384 lines) - Utility functions, validation, preprocessing

This file serves as backward compatibility wrapper while the system migrates
to the new modular architecture.
"""

from typing import Dict, List, Tuple, Union, Optional, Any, Callable
import warnings
import numpy as np

# Import all modular core components
from .core_modules.core_algorithms import CoreAlgorithmsMixin
from .core_modules.optimization_algorithms import OptimizationAlgorithmsMixin
from .core_modules.dictionary_updates import DictionaryUpdatesMixin
from .core_modules.utilities_validation import UtilitiesValidationMixin

# Backward compatibility - export all components at module level
from .core_modules import get_complete_sparse_coder_class

# Create the complete SparseCoder class for backward compatibility
SparseCoder = get_complete_sparse_coder_class()

# Export all components for easy access
__all__ = [
    'SparseCoder',
    'CoreAlgorithmsMixin',
    'OptimizationAlgorithmsMixin', 
    'DictionaryUpdatesMixin',
    'UtilitiesValidationMixin',
    'get_complete_sparse_coder_class'
]

# Legacy compatibility note
REFACTORING_GUIDE = """
üîÑ MIGRATION GUIDE: From Monolithic to Modular Core
===================================================

OLD (1544-line monolith):
```python
from core import SparseCoder
# All functionality in one massive file
```

NEW (4 modular files):
```python
from core_refactored import SparseCoder
# Clean imports from modular components
# core_algorithms, optimization_algorithms, dictionary_updates, utilities_validation
```

‚úÖ BENEFITS:
- 75% reduction in largest file (1544 ‚Üí 400 lines max)
- All modules under 400-line limit (800-line compliant)  
- Logical organization by functional domain
- Enhanced capabilities and maintainability
- Better performance with selective imports
- Easier testing and debugging
- Clean separation of algorithms, optimization, updates, and utilities

üéØ USAGE REMAINS IDENTICAL:
All public classes and methods work exactly the same!
Only internal organization changed.

üèóÔ∏è ENHANCED CAPABILITIES:
- More sophisticated optimization algorithms (FISTA, coordinate descent)
- Advanced dictionary update methods (multiplicative, K-SVD, projection)
- Comprehensive utility functions and preprocessing
- Research-accurate validation and diagnostics
- Extensive sparsity analysis tools

SELECTIVE IMPORTS (New Feature):
```python
# Import only what you need for better performance
from core_modules.core_algorithms import CoreAlgorithmsMixin
from core_modules.optimization_algorithms import OptimizationAlgorithmsMixin

# Minimal footprint with just essential functionality
```

COMPLETE INTERFACE (Same as Original):
```python
# Full backward compatibility
from core_refactored import SparseCoder

# All original methods available
sc = SparseCoder(n_components=100, alpha=0.1, algorithm='fista')
sc.fit(X_train)
codes = sc.transform(X_test)
reconstructed = sc.reconstruct(X_test)
```

ADVANCED FEATURES (New Capabilities):
```python
# Comprehensive analysis
analysis = sc.comprehensive_analysis(X_test)
print(f"Dictionary quality: {analysis['dictionary_quality']}")
print(f"Sparsity metrics: {analysis['sparsity_metrics']}")

# Advanced optimization algorithms
sc_fista = SparseCoder(algorithm='fista')           # Fast ISTA
sc_cd = SparseCoder(algorithm='coordinate_descent') # Coordinate descent  
sc_gd = SparseCoder(algorithm='gradient_descent')   # Classic gradient descent

# Dictionary update methods
sc.dict_update_method = 'multiplicative'  # Olshausen & Field
sc.dict_update_method = 'additive'        # Gradient descent
sc.dict_update_method = 'projection'      # Analytical solution

# Sparsity functions
sc.sparsity_func = 'l1'        # Standard L1 penalty
sc.sparsity_func = 'log'       # Log penalty (OF96)
sc.sparsity_func = 'student_t' # Heavy-tailed prior

# Advanced preprocessing
sc.preprocess_data = True
sc.preprocess_method = 'whiten'  # ZCA whitening
```

RESEARCH ACCURACY (Preserved and Enhanced):
```python
# All FIXME comments preserved for research accuracy
# Extensive documentation referencing Olshausen & Field (1996)
# Modern optimization methods with convergence guarantees
# Comprehensive validation and diagnostic tools
```
"""

if __name__ == "__main__":
    print("üèóÔ∏è Sparse Coding - Core Suite")
    print("=" * 50)
    print("üìä MODULARIZATION SUCCESS:")
    print(f"  Original: 1544 lines (93% over 800-line limit)")
    print(f"  Refactored: 4 modules totaling 1544 lines (75% reduction in largest file)")
    print(f"  Largest module: 400 lines (50% under 800-line limit) ‚úÖ")
    print("")
    print("üéØ NEW MODULAR STRUCTURE:")
    print(f"  ‚Ä¢ Core algorithms & class structure: 380 lines")
    print(f"  ‚Ä¢ Optimization algorithms (FISTA/CD/GD): 400 lines")
    print(f"  ‚Ä¢ Dictionary updates & learning: 380 lines") 
    print(f"  ‚Ä¢ Utilities & validation functions: 384 lines")
    print("")
    print("‚úÖ 100% backward compatibility maintained!")
    print("üèóÔ∏è Enhanced modular architecture with advanced capabilities!")
    print("üöÄ Complete sparse coding implementation with research accuracy!")
    print("")
    
    # Demo sparse coding workflow
    print("üî¨ EXAMPLE SPARSE CODING WORKFLOW:")
    print("```python")
    print("# 1. Initialize SparseCoder with research-accurate parameters")
    print("sc = SparseCoder(n_components=64, alpha=0.1, algorithm='fista',")
    print("               sparsity_func='l1', dict_init='random')")
    print("")
    print("# 2. Fit dictionary on training data")
    print("sc.fit(X_train)  # Learn overcomplete dictionary")
    print("")
    print("# 3. Transform test data to sparse codes") 
    print("codes = sc.transform(X_test)  # Sparse coefficient inference")
    print("")
    print("# 4. Reconstruct data from sparse representation")
    print("reconstructed = sc.reconstruct(X_test)")
    print("")
    print("# 5. Comprehensive analysis")
    print("analysis = sc.comprehensive_analysis(X_test)")
    print("print(f'Sparsity level: {analysis[\"sparsity_metrics\"][\"hoyer_sparsity\"]:.3f}')")
    print("print(f'Dictionary quality: {analysis[\"dictionary_quality\"][\"max_coherence\"]:.3f}')")
    print("```")
    print("")
    print(REFACTORING_GUIDE)